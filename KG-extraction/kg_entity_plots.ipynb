{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 20:08:25.072384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-01 20:08:27.082100: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-01 20:08:27.082303: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-01 20:08:27.082315: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from bert import QA\n",
    "import os\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import subprocess\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import networkx as nx\n",
    "import json\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import string\n",
    "\n",
    "import os\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../../data\"\n",
    "# filename = 'zelda-botw'\n",
    "# filename = 'resolved_zelda_botw'\n",
    "filename = 'resolved_TES_Oblivian'\n",
    "# filename = 'rapunzel'\n",
    "# filename = 'resolved_rapunzel'\n",
    "# filename = '01_the_fellowship_of_the_ring'\n",
    "# filename = '02_the_two_towers'\n",
    "# filename = '03_the_return_of_the_king'\n",
    "# filename = 'little-red-riding-hood'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGraph(file):\n",
    "    with open(file, 'r') as fp:\n",
    "        # G = nx.parse_edgelist(, nodetype = int)\n",
    "\n",
    "        dump = fp.read()\n",
    "        j = json.loads(dump)\n",
    "        locs = j.keys()\n",
    "        objs = []\n",
    "        for loc in j.values():\n",
    "            objs += loc['objects']\n",
    "    return locs, objs, []\n",
    "\n",
    "location_primer = \"Where is the location in the story?\"\n",
    "character_primer = \"Who is somebody in the story?\"\n",
    "object_primer = \"What is an object in the story?\"\n",
    "\n",
    "loc2loc_templates = [\"What location is next to {} in the story?\"]\n",
    "\n",
    "loc2obj_templates = [\"What is in {} in the story?\", ]\n",
    "obj2loc_templates = [\"What location is {} in the story?\", ]\n",
    "\n",
    "loc2char_templates = [\"Who is in {} in the story?\", ]\n",
    "char2loc_templates = [\"What location is {} in the story?\", ]\n",
    "\n",
    "obj2char_templates = [\"Who has {} in the story?\", ]\n",
    "\n",
    "articles = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class World:\n",
    "    def __init__(self, args):\n",
    "        '''\n",
    "        Initialize the world KG with the given entities and relations, and set up arguments.\n",
    "        params:\n",
    "            `locs`: list of locations\n",
    "            `chars`: list of characters\n",
    "            `objs`: list of objects\n",
    "            `relations`: list of relations\n",
    "            `args`: arguments\n",
    "        '''\n",
    "        self.graph = nx.Graph()  # create base NX graph\n",
    "        self.current_graph = nx.Graph()  # create context NX graph\n",
    "\n",
    "        self.entities = {  # dictionary of location, object and character entites\n",
    "            'locations': set(),\n",
    "            'objects': set(),\n",
    "            'characters': set()\n",
    "        }\n",
    "        self.relations = []  # list of relations\n",
    "        self.plots = []  # list of plots\n",
    "\n",
    "        random.seed(args.seed)  # set seed for reproducibility\n",
    "\n",
    "        self.nsamples = args.nsamples\n",
    "        self.write_sfdp = args.write_sfdp\n",
    "        self.context_lines = args.context_lines  # Number of lines of story to read at once\n",
    "        \n",
    "        self.load_cutoffs(args.cutoffs)  # load cutoffs from parameter\n",
    "        self.load_story(args.input_text)  # load story from parameter \n",
    "        self.next_context()  # load first context lines      \n",
    "\n",
    "        self.model = QA('model/albert-large-squad')\n",
    "\n",
    "\n",
    "    def load_cutoffs(self, cutoffs):\n",
    "        '''\n",
    "        Load cutoffs from parameter.\n",
    "        params:\n",
    "            `cutoffs`: either a string ['`fairy`', '`mystery`'] or \n",
    "            a list of 3 cutoff decimals for [character, location, object] respectively.\n",
    "        '''\n",
    "        if cutoffs == 'fairy':\n",
    "            self.cutoffs = [6.5, -7, -5]  # fairy\n",
    "        elif cutoffs == 'mystery':\n",
    "            self.cutoffs = [3.5, -7.5, -6]  # mystery\n",
    "        else:\n",
    "            self.cutoffs = [float(i) for i in cutoffs.split()]\n",
    "            assert len(self.cutoffs) == 3\n",
    "\n",
    "\n",
    "    def load_story(self, input_text):\n",
    "        '''\n",
    "        Load story from parameter.\n",
    "        params:\n",
    "            `input_text`: path to story text file\n",
    "        '''\n",
    "        with open(input_text, 'r') as f:\n",
    "            doc = f.readlines()\n",
    "            doc = ' '.join([x.strip() for x in doc])\n",
    "\n",
    "        self.story = tokenize.sent_tokenize(doc)  # split into sentences\n",
    "        self.remaining_story = self.story\n",
    "    \n",
    "    def next_context(self):\n",
    "        '''\n",
    "        Load the next `context_lines` lines of the story.\n",
    "        '''\n",
    "        if self.context_lines == 'all':\n",
    "            self.context = ' '.join(self.remaining_story)\n",
    "            self.remaining_story = []\n",
    "        else:\n",
    "            self.context = ' '.join(self.remaining_story[:self.context_lines])\n",
    "            self.remaining_story = self.remaining_story[self.context_lines:]\n",
    "        self.unmasked_context = self.context\n",
    "\n",
    "\n",
    "    def is_connected(self):\n",
    "        '''\n",
    "        Check if the current world graph is connected.\n",
    "        '''\n",
    "        return len(list(nx.connected_components(self.graph))) == 1\n",
    "\n",
    "\n",
    "    def query(self, context, query, nsamples=10, cutoff=8):\n",
    "        '''\n",
    "        Query the model for the top `nsamples` candidates for the given `query`.\n",
    "        params:\n",
    "            `query`: query string\n",
    "            `nsamples`: maximum number of candidates to return\n",
    "            `cutoff`: cutoff for the model\n",
    "        '''\n",
    "        return self.model.predictTopK(context, query, nsamples, cutoff)\n",
    "\n",
    "\n",
    "    def generateNeighbors(self, nsamples=100):\n",
    "        '''\n",
    "        Retrieve relation candidates for each entity in the world graph.\n",
    "        params:\n",
    "            `nsamples`: maximum number of candidates to return\n",
    "        '''\n",
    "        self.candidates = {}\n",
    "        for u in self.current_graph.nodes:\n",
    "            self.candidates[u] = {}\n",
    "            if self.current_graph.nodes[u]['type'] == \"location\":\n",
    "                self.candidates[u]['location'] = self.query(self.context, random.choice(loc2loc_templates).format(u), nsamples, self.cutoffs[1])\n",
    "                self.candidates[u]['object'] = self.query(self.context, random.choice(loc2obj_templates).format(u), nsamples, self.cutoffs[2])\n",
    "                self.candidates[u]['character'] = self.query(self.context, random.choice(loc2char_templates).format(u), nsamples,self.cutoffs[0])\n",
    "            if self.current_graph.nodes[u]['type'] == \"object\":\n",
    "                self.candidates[u]['location'] = self.query(self.context, random.choice(obj2loc_templates).format(u), nsamples, self.cutoffs[1])\n",
    "                self.candidates[u]['character'] = self.query(self.context, random.choice(obj2char_templates).format(u), nsamples, self.cutoffs[0])\n",
    "            if self.current_graph.nodes[u]['type'] == \"character\":\n",
    "                self.candidates[u]['location'] = self.query(self.context, random.choice(char2loc_templates).format(u), nsamples, self.cutoffs[1])\n",
    "\n",
    "\n",
    "    def relatedness(self, u, v):\n",
    "        '''\n",
    "        Compute the relatedness between two entities. Calculated as :math:`P(x,u) = [p(x,u)+o(u,x)]/2`\n",
    "        params:\n",
    "            `u`: entity 1\n",
    "            `v`: entity 2\n",
    "        '''\n",
    "        s = self.get_rel_prob(u, v) \n",
    "        s += self.get_rel_prob(v, u)\n",
    "        return s\n",
    "\n",
    "\n",
    "    def get_rel_prob(self, u, v):\n",
    "        s = 0\n",
    "        v_type = self.current_graph.nodes[v]['type']\n",
    "        if u not in self.candidates or v_type not in self.candidates[u]:\n",
    "            return s\n",
    "        u2v, probs = self.candidates[u][v_type]\n",
    "        if u2v is not None:\n",
    "            for c, p in zip(u2v, probs):\n",
    "                a = set(c.text.split()).difference(articles)\n",
    "                b = set(v.split()).difference(articles)\n",
    "\n",
    "                # find best intersect\n",
    "                best_intersect = 0\n",
    "                for x in self.current_graph.nodes:\n",
    "                    xx = set(x.split()).difference(articles)\n",
    "                    best_intersect = max(best_intersect, len(a.intersection(xx)))\n",
    "\n",
    "                # increment if answer is best match BoW\n",
    "                if len(a.intersection(b)) == best_intersect:\n",
    "                    s += len(a.intersection(b)) * p\n",
    "        return s\n",
    "\n",
    "\n",
    "    def extractEntity(self, query, threshold=0.05, cutoff=0):\n",
    "        '''\n",
    "        Extract all entities from a query result.\n",
    "        params:\n",
    "            `query`: query string\n",
    "            `threshold`: minimum probability for a candidate to be considered\n",
    "            `cutoff`: cutoff for the model\n",
    "        '''\n",
    "        preds, probs = self.query(self.context, query, self.nsamples, cutoff)\n",
    "\n",
    "        if preds is None:\n",
    "            print(\"NO ANSWER FOUND\")\n",
    "            return None, 0\n",
    "\n",
    "        for pred, prob in zip(preds, probs):\n",
    "            t = pred.text\n",
    "            p = prob\n",
    "            print('> ', t, p)\n",
    "            if len(t) < 1:\n",
    "                continue\n",
    "            if p > threshold and \"MASK\" not in t:\n",
    "                # find a more minimal candidate if possible\n",
    "                for pred, prob in zip(preds, probs):\n",
    "                    if t != pred.text and pred.text in t and prob > threshold and len(pred.text) > 2:\n",
    "                        t = pred.text\n",
    "                        p = prob\n",
    "                        break\n",
    "\n",
    "                t = t.strip(string.punctuation)\n",
    "                remove = t\n",
    "\n",
    "                # take out leading articles for cleaning\n",
    "                words = t.split()\n",
    "                if words[0].lower() in articles:\n",
    "                    remove = \" \".join(words[1:])\n",
    "                    words[0] = words[0].lower()\n",
    "                    t = \" \".join(words[1:])\n",
    "                if remove.strip() == '':\n",
    "                    print(\"NO ANSWER FOUND\")\n",
    "                    return None, 0\n",
    "                print(remove)\n",
    "\n",
    "                self.context = self.context.replace(remove, '[MASK]').replace('  ', ' ').replace(' .', '.')\n",
    "                return t, p\n",
    "\n",
    "        return None, 0\n",
    "\n",
    "\n",
    "    def generate(self, filename=None):\n",
    "        '''\n",
    "        Generate the world graph from the entire story by parsing it # `context_lines` at a time.\n",
    "        Extracts entities, relations between entities and potential plots.\n",
    "        params:\n",
    "            `filename`: path of file to save extracted entities as (JSON)\n",
    "        '''\n",
    "        # set initial threshold\n",
    "        threshold = 0.05\n",
    "\n",
    "        while len(self.context) != 0:\n",
    "            print(f'Current context: {self.context}')\n",
    "\n",
    "            # add locations\n",
    "            locs = self.extract('locations', location_primer, threshold, self.cutoffs[1])\n",
    "            # add objects\n",
    "            objs = self.extract('objects', object_primer, threshold, self.cutoffs[2])\n",
    "            # add characters\n",
    "            chars = self.extract('characters', character_primer, threshold, self.cutoffs[0])\n",
    "            \n",
    "            self.current_graph.clear()\n",
    "            self.current_graph.add_nodes_from(locs, type='location', fillcolor=\"yellow\", style=\"filled\")\n",
    "            self.current_graph.add_nodes_from(objs, type='object', fillcolor=\"white\", style=\"filled\")\n",
    "            self.current_graph.add_nodes_from(chars, type='character', fillcolor=\"orange\", style=\"filled\")\n",
    "            \n",
    "            self.context = self.unmasked_context\n",
    "            self.autocomplete()\n",
    "            \n",
    "            self.entities['locations'].update(locs)\n",
    "            self.entities['objects'].update(objs)\n",
    "            self.entities['characters'].update(chars)\n",
    "            self.next_context()\n",
    "            print('-' * 20 + '\\n')\n",
    "\n",
    "        self.entities['locations'] = list(self.entities['locations'])\n",
    "        self.entities['objects'] = list(self.entities['objects'])\n",
    "        self.entities['characters'] = list(self.entities['characters'])\n",
    "        self.entities['relations'] = self.relations\n",
    "        self.entities['plots'] = self.plots\n",
    "        if filename is not None:\n",
    "            with open(filename, 'w') as f:\n",
    "                json.dump(self.entities, f, indent=4, sort_keys=False)\n",
    "\n",
    "\n",
    "    def extract(self, entity_type, primer, threshold, cutoff):\n",
    "        entity_list = []\n",
    "        print('-' * 5 + f'\\t{entity_type}\\t' + '-' * 5)\n",
    "        t, _ = self.extractEntity(primer, threshold=threshold, cutoff=cutoff)\n",
    "        while t is not None and len(t) > 1:\n",
    "            entity_list.append(t)\n",
    "            t, _ = self.extractEntity(primer, threshold=threshold, cutoff=cutoff)\n",
    "        print('-' * 20 + '\\n')\n",
    "        self.context = self.unmasked_context\n",
    "        return entity_list\n",
    "\n",
    "\n",
    "    def autocomplete(self):\n",
    "        '''\n",
    "        Autocomplete the current contextual graph by adding relations between entities.\n",
    "        '''\n",
    "        self.generateNeighbors(self.nsamples)\n",
    "        print('-' * 5 + '\\trelations\\t' + '-' * 5)\n",
    "        entities = list(self.current_graph.nodes)\n",
    "        best = (-1, '', '')\n",
    "\n",
    "        for u in entities:\n",
    "            u_type = self.current_graph.nodes[u]['type']\n",
    "            # print(f'Searching relations for {u}')\n",
    "            for v in list(self.current_graph.nodes):\n",
    "                v_type = self.current_graph.nodes[v]['type']\n",
    "                if u == v or (u_type != 'location' and u_type == v_type):\n",
    "                    continue\n",
    "                uvrel = self.relatedness(u, v)\n",
    "                best = max(best, (uvrel, v, v_type))\n",
    "            \n",
    "            s, v, v_type = best\n",
    "\n",
    "            if s <= 0:\n",
    "                # print(f'No relations found for {u}')\n",
    "                continue\n",
    "                    \n",
    "            if u_type == 'location':\n",
    "                if v_type == 'location':\n",
    "                    rel_type = \"connected to\"\n",
    "                else:\n",
    "                    rel_type = \"located in\"\n",
    "            else:\n",
    "                rel_type = \"has\"\n",
    "            \n",
    "            self.check_and_add_world_relation(v, u, rel_type)            \n",
    "\n",
    "\n",
    "    def check_and_add_world_relation(self, v, u, rel_type):\n",
    "        '''\n",
    "        Check if the relation is already present in the graph. \n",
    "        If present, add to plot graph, otherwise normally add to world graph\n",
    "        '''\n",
    "        u_type = self.current_graph.nodes[u]['type']\n",
    "        v_type = self.current_graph.nodes[v]['type']\n",
    "\n",
    "        if u not in self.graph:\n",
    "            self.graph.add_node(u, type=u_type)\n",
    "        if v not in self.graph:\n",
    "            self.graph.add_node(v, type=v_type)\n",
    "\n",
    "        if u_type == 'location':\n",
    "            if v_type == 'location':\n",
    "                # if both are location, just add it the relation\n",
    "                rel_type = 'connected to'\n",
    "                rel_triplet = (v, rel_type, u)\n",
    "                print(f'Adding relation: {rel_triplet}')\n",
    "                self.relations.append(rel_triplet)\n",
    "                self.graph.add_edge(v, u, label=rel_type)\n",
    "            else:\n",
    "                # u is location, v is char/obj\n",
    "                rel_type = 'located in'\n",
    "                rel_triplet = (v, rel_type, u)\n",
    "                print(f'Adding relation: {rel_triplet}')\n",
    "                for c_node in self.graph[v]:\n",
    "                    existing_label = self.graph[v][c_node]['label']\n",
    "                    if existing_label == rel_type:\n",
    "                        print(f'Found existing relation: {v}, {rel_type}, {c_node}')\n",
    "                        if c_node != u:\n",
    "                            # if v is 'located in' some other location (c_node) before this point,\n",
    "                            # v's location is changed, put it as an event\n",
    "                            print(f'Updating new relation: {rel_triplet}')\n",
    "                            self.plots.append({'before': (v, existing_label, c_node), 'after': rel_triplet})\n",
    "                self.graph.add_edge(v, u, label=rel_type)\n",
    "                self.relations.append(rel_triplet)\n",
    "        \n",
    "        elif u_type == 'charater' and v_type == 'object':\n",
    "            rel_type = 'has'\n",
    "            rel_triplet = (u, rel_type, v)\n",
    "            print(f'Adding relation: {rel_triplet}')\n",
    "            for c_node in self.graph[v]:\n",
    "                existing_label = self.graph[v][c_node]['label']\n",
    "                if existing_label == rel_type:\n",
    "                    print(f'Found existing relation: {c_node}, {rel_type}, {v}')\n",
    "                    if c_node != u:\n",
    "                        # if some other char (c_node) has v before this point, \n",
    "                        # v's ownership has changed, put it as event\n",
    "                        print(f'Updating new relation: {rel_triplet}')\n",
    "                        self.plots.append({'before': (c_node, existing_label, v), 'after': rel_triplet})\n",
    "            self.graph.add_edge(v, u, label=rel_type)\n",
    "            self.relations.append(rel_triplet)\n",
    "        \n",
    "        elif u_type == 'object' and v_type == 'character':\n",
    "            rel_type = 'has'\n",
    "            rel_triplet = (v, rel_type, u)\n",
    "            print(f'Adding relation: {rel_triplet}')\n",
    "            for c_node in self.graph[u]:\n",
    "                existing_label = self.graph[u][c_node]['label']\n",
    "                if existing_label == rel_type:\n",
    "                    print(f'Found existing relation: {v}, {rel_type}, {c_node}')\n",
    "                    if c_node != u:\n",
    "                        # if some other char (c_node) has u before this point, \n",
    "                        # u's ownership has changed, put it as event\n",
    "                        print(f'Updating new relation: {rel_triplet}')\n",
    "                        self.plots.append({'before': (v, existing_label, c_node), 'after': rel_triplet})\n",
    "            self.graph.add_edge(v, u, label=rel_type)\n",
    "            self.relations.append(rel_triplet)\n",
    "            \n",
    "        elif v_type == 'location':\n",
    "            # u is char/obj, v is location\n",
    "            rel_type = 'located in'\n",
    "            rel_triplet = (u, rel_type, v)\n",
    "            print(f'Adding relation: {rel_triplet}')\n",
    "            for c_node in self.graph[u]:\n",
    "                existing_label = self.graph[u][c_node]['label']\n",
    "                if existing_label == rel_type:\n",
    "                    print(f'Found existing relation: {u}, {rel_type}, {c_node}')\n",
    "                    if c_node != v:\n",
    "                        # if u is 'located in' some other location (c_node) before this point,\n",
    "                        # u's location is changed, put it as an event\n",
    "                        print(f'Updating new relation: {rel_triplet}')\n",
    "                        self.plots.append({'before': (u, existing_label, c_node), 'after': rel_triplet})\n",
    "            self.graph.add_edge(v, u, label=rel_type)\n",
    "            self.relations.append(rel_triplet)\n",
    "\n",
    "\n",
    "    def export(self, filename=\"graph.dot\"):\n",
    "        nx.nx_pydot.write_dot(self.graph, filename)\n",
    "        nx.write_gml(self.graph, \"graph.gml\", stringizer=None)\n",
    "\n",
    "\n",
    "    def draw(self, filename=\"./graph.svg\"):\n",
    "        self.export()\n",
    "\n",
    "        if self.write_sfdp:\n",
    "            cmd = \"sfdp -x -Goverlap=False -Tsvg graph.dot\".format(filename)\n",
    "            returned_value = subprocess.check_output(cmd, shell=True)\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(returned_value)\n",
    "            cmd = \"inkscape -z -e {}.png {}.svg\".format(filename[:-4], filename[:-4])\n",
    "            returned_value = subprocess.check_output(cmd, shell=True)\n",
    "        else:\n",
    "            nx.draw(self.graph, with_labels=True)\n",
    "            plt.savefig(filename[:-4] + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Args:\n",
    "    def __init__(self, args):\n",
    "        self.input_text = args['input_text']\n",
    "        self.seed = args['seed']\n",
    "        self.nsamples = args['nsamples']\n",
    "        self.cutoffs = args['cutoffs']\n",
    "        self.write_sfdp = args['write_sfdp']\n",
    "        self.random = args['random']\n",
    "        self.context_lines = args['context_lines']\n",
    "                \n",
    "args = Args({\n",
    "    'input_text': os.path.join(data_dir, f'{filename}.txt'),\n",
    "    'seed' : 0,\n",
    "    'nsamples' : 14,\n",
    "    'cutoffs' : '12 15 13',\n",
    "    'write_sfdp': False,\n",
    "    'random': False,\n",
    "    'context_lines': 10\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current context: Alval Uvani is dead, just like all the others. Silencer continue to impress me, Silencer, and I am only too eager to indulge Silencer's homicidal instincts. Silencer's next target is a savage Nord barbarian, living alone and exposed at a small campsite on the summit of Gnoll Mountain. a savage Nord barbarian, living alone and exposed at a small campsite on the summit of Gnoll Mountain, savagely butchered the chieftain of a mead hall on the island of Solstheim. the chieftain of a mead hall on the island of Solstheim's sister has forgone the Nord custom of extracting the monetary retribution of wergild, and instead wants a savage Nord barbarian, living alone and exposed at a small campsite on the summit of Gnoll Mountain to pay with a savage Nord barbarian, living alone and exposed at a small campsite on the summit of Gnoll Mountain's life. Silencer, Silencer, will help put The chieftain's sister's family at peace. Silencer are to go to Gnoll Mountain, locate a savage Nord barbarian, living alone and exposed at a small campsite on the summit of Gnoll Mountain, and send a savage Nord barbarian, living alone and exposed at a small campsite on the summit of Gnoll Mountain's soul to the great beyond. When a savage Nord barbarian, living alone and exposed at a small campsite on the summit of Gnoll Mountain has been executed, journey to the ancient ruin of Nornal. In the flooded section of the ancient ruin of Nornal Silencer will find a chest, submerged in the water. As Silencer may have guessed, a chest, submerged in the water contains Silencer's reward for killing a savage Nord barbarian, living alone and exposed at a small campsite on the summit of Gnoll Mountain, 500 gold, and Silencer's next contract.\n",
      "-----\tlocations\t-----\n",
      ">  the ancient ruin of Nornal. 0.4361505304891842\n",
      "ancient ruin of Nornal\n",
      ">  Gnoll Mountain. 0.3565644919902537\n",
      "Gnoll Mountain\n",
      ">  the great beyond. 0.5686968646108892\n",
      "great beyond\n",
      ">  Solstheim. 0.6026134974676658\n",
      "Solstheim\n",
      "NO ANSWER FOUND\n",
      "--------------------\n",
      "\n",
      "-----\tobjects\t-----\n",
      ">  a chest, 0.48188718415790727\n",
      "chest\n",
      "NO ANSWER FOUND\n",
      "--------------------\n",
      "\n",
      "-----\tcharacters\t-----\n",
      ">  Alval Uvani 0.8173446467044678\n",
      "Alval Uvani\n",
      ">  wergild, 0.9011292781781389\n",
      "wergild\n",
      "NO ANSWER FOUND\n",
      "--------------------\n",
      "\n",
      "-----\trelations\t-----\n",
      "Adding relation: ('Gnoll Mountain', 'connected to', 'ancient ruin of Nornal')\n",
      "Adding relation: ('ancient ruin of Nornal', 'connected to', 'Gnoll Mountain')\n",
      "Adding relation: ('ancient ruin of Nornal', 'connected to', 'great beyond')\n",
      "Adding relation: ('ancient ruin of Nornal', 'connected to', 'Solstheim')\n",
      "Adding relation: ('chest', 'located in', 'ancient ruin of Nornal')\n",
      "Adding relation: ('Alval Uvani', 'located in', 'ancient ruin of Nornal')\n",
      "Adding relation: ('wergild', 'located in', 'ancient ruin of Nornal')\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "world = World(args)\n",
    "world.generate(os.path.join(f\"./outputs/{filename}.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ancient ruin of Nornal\" is location\n",
      "\t connected to \"Gnoll Mountain\"\n",
      "\t connected to \"great beyond\"\n",
      "\t connected to \"Solstheim\"\n",
      "\t located in \"chest\"\n",
      "\t located in \"Alval Uvani\"\n",
      "\t located in \"wergild\"\n",
      "\"Gnoll Mountain\" is location\n",
      "\t connected to \"ancient ruin of Nornal\"\n",
      "\"great beyond\" is location\n",
      "\t connected to \"ancient ruin of Nornal\"\n",
      "\"Solstheim\" is location\n",
      "\t connected to \"ancient ruin of Nornal\"\n",
      "\"chest\" is object\n",
      "\t located in \"ancient ruin of Nornal\"\n",
      "\"Alval Uvani\" is character\n",
      "\t located in \"ancient ruin of Nornal\"\n",
      "\"wergild\" is character\n",
      "\t located in \"ancient ruin of Nornal\"\n"
     ]
    }
   ],
   "source": [
    "for n in world.graph.nodes:\n",
    "    print(f'\"{n}\" is {world.graph.nodes[n][\"type\"]}')\n",
    "    for a in world.graph.adj[n]:\n",
    "    \tprint(f'\\t {world.graph.adj[n][a][\"label\"]} \"{a}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "g.add_node('a')\n",
    "g.add_node('b')\n",
    "g.add_node('c', type='gg')\n",
    "g.add_edge('a','b', type='conn')\n",
    "g.add_edge('a','c', type='conn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "askBert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
