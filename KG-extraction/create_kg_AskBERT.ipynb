{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AskBERT\n",
    "\n",
    "Using [AskBERT](https://github.com/rajammanabrolu/WorldGeneration/tree/master/neural-based/KG-extraction), [BERT-SQuAD](https://github.com/kamalkraj/BERT-SQuAD). \n",
    "\n",
    "Paper: Ammanabrolu, Prithviraj, Wesley Cheung, Dan Tu, William Broniec, and Mark Riedl. 2020. “Bringing Stories Alive: Generating Interactive Fiction Worlds.” Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment 16 (1): 3–9. https://doi.org/10.1609/aiide.v16i1.7400.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from bert import QA\n",
    "from nltk import tokenize\n",
    "nltk.download('punkt')## Inference on AskBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../../data\"\n",
    "\n",
    "filename = 'zelda-botw'\n",
    "# filename = 'resolved_zelda_botw'\n",
    "# filename = 'rapunzel'\n",
    "# filename = 'resolved_rapunzel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "import os\n",
    "# nltk.download('punkt')\n",
    "from nltk import tokenize\n",
    "\n",
    "with open(os.path.join(data_dir, f\"{filename}.txt\")) as f:\n",
    "    doc = f.readlines()\n",
    "    doc = ' '.join([x.strip() for x in doc])\n",
    "    doc = tokenize.sent_tokenize(doc) # split into sentences\n",
    "\n",
    "for s in doc:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import QA\n",
    "import os\n",
    "\n",
    "model = QA('model/albert-large-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, \"resolved_zelda_botw.txt\")) as f:\n",
    "    doc = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_query_results(doc, query):\n",
    "    answer = model.predict(doc, query)\n",
    "    for preds in answer[0]:\n",
    "        print(preds)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"After escaping the confines of the Great Plateau, Link is directed to meet the wise Sheikah elder Impa, and learn about the Guardians and Divine Beasts: 10,000 years prior the Guardians and Divine Beasts were created and successfully used by another Hero and another Princess to defeat a great evil known as the Calamity Ganon. But throughout the ages, knowledge about the Guardians and Divine Beasts was lost until excavations in the ruined country of Hyrule Kingdom brought the Guardians and Divine Beasts to light once more, coinciding with the expected return of a great evil known as the Calamity Ganon a hundred years ago. Guardians were reactivated and four Champions were chosen to control Divine Beasts: the Zora princess Mipha, the Goron warrior Daruk, the Gerudo chief Urbosa, and the Rito archer Revali. All the while, Zelda, who is the daughter of King Rhoam was unsuccessfully trying to gain access to Zelda, who is the daughter of King Rhoam's own prophesied powers, accompanied on Zelda, who is the daughter of King Rhoam's quests by Zelda, who is the daughter of King Rhoam's knight, the Hylian Champion Link. When a great evil known as the Calamity Ganon ultimately attacked, a great evil known as the Calamity Ganon devastated the ruined country of Hyrule Kingdom by taking control of the ancient machines and turning the ancient machines against the Hyruleans. As a last resort, Zelda, who is the daughter of King Rhoam was able to place Link in the Shrine of Resurrection and use Zelda, who is the daughter of King Rhoam's awoken sealing powers to trap Zelda, who is the daughter of King Rhoam with a great evil known as the Calamity Ganon in Hyrule Castle.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc2loc_templates = \"What location is next to {} in the story?\"\n",
    "\n",
    "loc2obj_templates = \"What object is in {} in the story?\" \n",
    "obj2loc_templates = \"What location is the object {} in the story?\"\n",
    "\n",
    "loc2char_templates = \"Who is in {} in the story?\"\n",
    "char2loc_templates = \"What location is {} in the story?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_template = \"Who is somebody in the story?\"\n",
    "loc_template = \"Where is the location in the story?\"\n",
    "obj_template = \"What is an object in the story?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = ['Zelda', 'Link', 'daughter', 'King of Hyrule, King Rhoam', 'Rhoam', 'spirit of the deceased King', 'voice', 'Old Man', 'Sheikah', 'Impa', 'King', 'Revali', 'Daruk', 'Urbosa', 'Mipha']\n",
    "locations = ['Hyrule Kingdom', 'Great Plateau', 'Hyrule Castle', 'ruined country', 'Temple of Time', 'Shrine of Resurrection', 'campfire']\n",
    "objects = ['Spirit Orbs', \"Old Man's Paraglider\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_loc = random.choice(locations)\n",
    "print(selected_loc)\n",
    "loc_query = print_query_results(doc, obj2loc_templates.format('shrines'))\n",
    "print(loc_query[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_query = print_query_results(doc, 'Where is ruined country?')\n",
    "print(char_query[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_query = print_query_results(doc, 'What location is paraglider in the story?')\n",
    "print(a_query[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import QA\n",
    "import os\n",
    "\n",
    "# !/usr/bin/env python3\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import subprocess\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import networkx as nx\n",
    "import json\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "def readGraph(file):\n",
    "    with open(file, 'r') as fp:\n",
    "        # G = nx.parse_edgelist(, nodetype = int)\n",
    "\n",
    "        dump = fp.read()\n",
    "        j = json.loads(dump)\n",
    "        locs = j.keys()\n",
    "        objs = []\n",
    "        for loc in j.values():\n",
    "            objs += loc['objects']\n",
    "    return locs, objs, []\n",
    "\n",
    "\n",
    "loc2loc_templates = [\"What location is next to {} in the story?\"]\n",
    "loc2obj_templates = [\"What is in {} in the story?\", ]\n",
    "loc2char_templates = [\"Who is in {} in the story?\", ]\n",
    "\n",
    "obj2loc_templates = [\"What location is {} in the story?\", ]\n",
    "obj2char_templates = [\"Who has {} in the story?\", ]\n",
    "\n",
    "char2loc_templates = [\"What location is {} in the story?\", ]\n",
    "\n",
    "conjunctions = ['and', 'or', 'nor']\n",
    "articles = [\"the\", 'a', 'an', 'his', 'her', 'their', 'my', 'its', 'those', 'these', 'that', 'this', 'the']\n",
    "pronouns = [\"He\", \"She\", \"he\", \"she\"]\n",
    "\n",
    "\n",
    "class World:\n",
    "    def __init__(self, locs, chars, objs, relations, args):\n",
    "        self.graph = nx.Graph()\n",
    "        self.graph.add_nodes_from(locs, type='location', fillcolor=\"yellow\", style=\"filled\")\n",
    "        self.graph.add_nodes_from(chars, type='character', fillcolor=\"orange\", style=\"filled\")\n",
    "        self.graph.add_nodes_from(objs, type='object', fillcolor=\"white\", style=\"filled\")\n",
    "        self.graph.add_edges_from(relations)\n",
    "\n",
    "        self.locations = {v for v in locs}\n",
    "        self.objects = {v for v in objs}\n",
    "        self.characters = {v for v in chars}\n",
    "        \n",
    "        self.relations = relations\n",
    "\n",
    "        self.context_lines = 8\n",
    "\n",
    "        self.args = args\n",
    "        self.cutoffs = self.args.cutoffs\n",
    "\n",
    "        if self.args.cutoffs == 'fairy':\n",
    "            self.cutoffs = [6.5, -7, -5]  # fairy\n",
    "        elif self.args.cutoffs == 'mystery':\n",
    "            self.cutoffs = [3.5, -7.5, -6]  # mystery\n",
    "        else:\n",
    "            self.cutoffs = [float(i) for i in self.args.cutoffs.split()]\n",
    "            assert len(self.cutoffs) == 3\n",
    "\n",
    "        with open(args.input_text) as f:\n",
    "            self.input_text = f.read()\n",
    "        \n",
    "        self.story = self.input_text\n",
    "\n",
    "        print(self.story)\n",
    "\n",
    "        self.model = QA('model/albert-large-squad')\n",
    "\n",
    "    def is_connected(self):\n",
    "        return len(list(nx.connected_components(self.graph))) == 1\n",
    "\n",
    "    def query(self, query, nsamples=10, cutoff=8):\n",
    "        return self.model.predictTopK(self.input_text, query, nsamples, cutoff)\n",
    "\n",
    "    def generateNeighbors(self, nsamples=100):\n",
    "        self.candidates = {}\n",
    "        for u in self.graph.nodes:\n",
    "            self.candidates[u] = {}\n",
    "            if self.graph.nodes[u]['type'] == \"location\":\n",
    "                self.candidates[u]['location'] = self.query(random.choice(loc2loc_templates).format(u), nsamples, self.cutoffs[1])\n",
    "                self.candidates[u]['object'] = self.query(random.choice(loc2obj_templates).format(u), nsamples, self.cutoffs[2])\n",
    "                self.candidates[u]['character'] = self.query(random.choice(loc2char_templates).format(u), nsamples,self.cutoffs[0])\n",
    "            if self.graph.nodes[u]['type'] == \"object\":\n",
    "                self.candidates[u]['location'] = self.query(random.choice(obj2loc_templates).format(u), nsamples, self.cutoffs[1])\n",
    "                self.candidates[u]['character'] = self.query(random.choice(obj2char_templates).format(u), nsamples, self.cutoffs[0])\n",
    "            if self.graph.nodes[u]['type'] == \"character\":\n",
    "                self.candidates[u]['location'] = self.query(random.choice(char2loc_templates).format(u), nsamples, self.cutoffs[1])\n",
    "\n",
    "    def relatedness(self, u, v, u_type='location', v_type='location'):\n",
    "\n",
    "        s = 0\n",
    "        u2v, probs = self.candidates[u][v_type]\n",
    "\n",
    "        if u2v is not None:\n",
    "            for c, p in zip(u2v, probs):\n",
    "                a = set(c.text.split()).difference(articles)\n",
    "                b = set(v.split()).difference(articles)\n",
    "\n",
    "                # find best intersect\n",
    "                best_intersect = 0\n",
    "                for x in self.graph.nodes:\n",
    "                    xx = set(x.split()).difference(articles)\n",
    "                    best_intersect = max(best_intersect, len(a.intersection(xx)))\n",
    "\n",
    "                # increment if answer is best match BoW\n",
    "                if len(a.intersection(b)) == best_intersect:\n",
    "                    s += len(a.intersection(b)) * p\n",
    "\n",
    "                # naive method\n",
    "                # s += len(a.intersection(b)) * p\n",
    "\n",
    "        v2u, probs = self.candidates[v][u_type]\n",
    "\n",
    "        if v2u is not None:\n",
    "            for c, p in zip(v2u, probs):\n",
    "                a = set(c.text.split()).difference(articles)\n",
    "                b = set(u.split()).difference(articles)\n",
    "\n",
    "                # find best intersect\n",
    "                best_intersect = 0\n",
    "                for x in self.graph.nodes:\n",
    "                    xx = set(x.split()).difference(articles)\n",
    "                    best_intersect = max(best_intersect, len(a.intersection(xx)))\n",
    "\n",
    "                # increment if answer is best match BoW\n",
    "                if len(a.intersection(b)) == best_intersect:\n",
    "                    s += len(a.intersection(b)) * p\n",
    "\n",
    "                # naive method\n",
    "                # s += len(a.intersection(b)) * p\n",
    "\n",
    "        return s\n",
    "\n",
    "    def extractEntity(self, query, threshold=0.05, cutoff=0):\n",
    "        preds, probs = self.query(query, self.args.nsamples, cutoff)\n",
    "\n",
    "        if preds is None:\n",
    "            print(\"NO ANSWER FOUND\")\n",
    "            return None, 0\n",
    "\n",
    "        for pred, prob in zip(preds, probs):\n",
    "            t = pred.text\n",
    "            p = prob\n",
    "            print('> ', t, p)\n",
    "            if len(t) < 1:\n",
    "                continue\n",
    "            if p > threshold and \"MASK\" not in t:\n",
    "\n",
    "                # find a more minimal candidate if possible\n",
    "                # TODO: IS IT REALLY NEEDED?\n",
    "                for pred, prob in zip(preds, probs):\n",
    "                    if t != pred.text and pred.text in t and prob > threshold and len(pred.text) > 2:\n",
    "                        t = pred.text\n",
    "                        p = prob\n",
    "                        break\n",
    "\n",
    "                t = t.strip(string.punctuation)\n",
    "                remove = t\n",
    "\n",
    "                # take out leading articles for cleaning\n",
    "                words = t.split()\n",
    "                if words[0].lower() in articles:\n",
    "                    remove = \" \".join(words[1:])\n",
    "                    words[0] = words[0].lower()\n",
    "                    t = \" \".join(words[1:])\n",
    "                print(remove)\n",
    "\n",
    "                self.input_text = self.input_text.replace(remove, '[MASK]').replace('  ', ' ').replace(' .', '.')\n",
    "                return t, p\n",
    "            # else:\n",
    "            # # find a more minimal candidate if possible\n",
    "            #     for pred, prob in zip(preds, probs):\n",
    "            #         if prob > threshold and \"MASK\" not in pred.text and len(pred.text) > 2 and pred.text in t:\n",
    "            #             t = pred.text.strip(string.punctuation)\n",
    "            #             p = prob\n",
    "            #             self.input_text = self.input_text.replace(t, '[MASK]').replace('  ', ' ').replace(' .', '.')\n",
    "            #             print(t, p)\n",
    "            #             return t, p\n",
    "\n",
    "        return None, 0\n",
    "\n",
    "    def generate(self, filename=\"entities.json\"):\n",
    "\n",
    "        locs = []\n",
    "        objs = []\n",
    "        chars = []\n",
    "\n",
    "        # set thresholds/cutoffs\n",
    "        threshold = 0.05\n",
    "\n",
    "        # save input text\n",
    "        tmp = self.input_text[:]\n",
    "\n",
    "        # add chars\n",
    "        print(\"=\" * 20 + \"\\tcharacters\\t\" + \"=\" * 20)\n",
    "        self.input_text = tmp\n",
    "        primer = \"Who is somebody in the story?\"\n",
    "        cutoff = self.cutoffs[0]\n",
    "        t, p = self.extractEntity(primer, threshold=threshold, cutoff=cutoff)\n",
    "        while t is not None and len(t) > 1:\n",
    "            chars.append(t)\n",
    "            t, p = self.extractEntity(primer, threshold=threshold, cutoff=cutoff)\n",
    "\n",
    "        # add locations\n",
    "        print(\"=\" * 20 + \"\\tlocations\\t\" + \"=\" * 20)\n",
    "        self.input_text = tmp\n",
    "        primer = \"Locations?\"\n",
    "        cutoff = self.cutoffs[1]\n",
    "        t, p = self.extractEntity(primer, threshold=threshold, cutoff=cutoff)\n",
    "        while t is not None and len(t) > 1:\n",
    "            locs.append(t)\n",
    "            t, p = self.extractEntity(primer, threshold=threshold, cutoff=cutoff)\n",
    "\n",
    "        # add objects\n",
    "        print(\"=\" * 20 + \"\\tobjects\\t\\t\" + \"=\" * 20)\n",
    "        self.input_text = tmp\n",
    "        primer = \"What is an object in the story?\"\n",
    "        cutoff = self.cutoffs[2]\n",
    "        t, p = self.extractEntity(primer, threshold=threshold, cutoff=cutoff)\n",
    "        while t is not None and len(t) > 1:\n",
    "            objs.append(t)\n",
    "            t, p = self.extractEntity(primer, threshold=threshold, cutoff=cutoff)\n",
    "        self.input_text = tmp\n",
    "\n",
    "        self.graph.add_nodes_from(locs, type='location', fillcolor=\"yellow\", style=\"filled\")\n",
    "        self.graph.add_nodes_from(chars, type='character', fillcolor=\"orange\", style=\"filled\")\n",
    "        self.graph.add_nodes_from(objs, type='object', fillcolor=\"white\", style=\"filled\")\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump({'characters':chars, 'locations':locs, 'objects':objs}, f, indent=4, sort_keys=False)\n",
    "        self.autocomplete()\n",
    "\n",
    "    def autocomplete(self):\n",
    "\n",
    "        self.generateNeighbors(self.args.nsamples)\n",
    "\n",
    "        print(\"=\" * 20 + \"\\trelations\\t\" + \"=\" * 20)\n",
    "        while not self.is_connected():\n",
    "            components = list(nx.connected_components(self.graph))\n",
    "            best = (-1, next(iter(components[0])), next(iter(components[1])))\n",
    "\n",
    "            main = components[0]\n",
    "\n",
    "            for u in main:\n",
    "                u_type = self.graph.nodes[u]['type']\n",
    "                # print(f'Searching relations for {u}')\n",
    "                for c in components[1:]:\n",
    "                    for v in c:\n",
    "                        v_type = self.graph.nodes[v]['type']\n",
    "                        if u_type != 'location' and u_type == v_type:\n",
    "                            continue\n",
    "                        uvrel = self.relatedness(u, v, u_type, v_type)\n",
    "                        best = max(best, (uvrel, u, v))\n",
    "                        # print(f'\\twith {v} {uvrel}')\n",
    "\n",
    "            _, u, v = best\n",
    "\n",
    "            # attach randomly if empty or specified\n",
    "            if _ == 0 or self.args.random:\n",
    "                candidates = []\n",
    "                for c in components[0]:\n",
    "                    if self.graph.nodes[c]['type'] == 'location':\n",
    "                        candidates.append(c)\n",
    "                u = random.choice(candidates)\n",
    "            u_type = self.graph.nodes[u]['type']\n",
    "            v_type = self.graph.nodes[v]['type']\n",
    "            \n",
    "            if u_type == 'location':\n",
    "                if v_type == 'location':\n",
    "                    rel_type = \"connected to\"\n",
    "                else:\n",
    "                    rel_type = \"present in\"\n",
    "            else:\n",
    "                rel_type = \"has\"\n",
    "            \n",
    "            print(\"{} {} {}\".format(v, rel_type, u))\n",
    "            self.graph.add_edge(v, u, label=type)\n",
    "            self.edge_labels[(v, u)] = rel_type\n",
    "\n",
    "    def export(self, filename=\"graph.dot\"):\n",
    "        nx.nx_pydot.write_dot(self.graph, filename)\n",
    "        nx.write_gml(self.graph, \"graph.gml\", stringizer=None)\n",
    "\n",
    "    def draw(self, filename=\"./graph.svg\"):\n",
    "        self.export()\n",
    "\n",
    "        if args.write_sfdp:\n",
    "            cmd = \"sfdp -x -Goverlap=False -Tsvg graph.dot\".format(filename)\n",
    "            returned_value = subprocess.check_output(cmd, shell=True)\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(returned_value)\n",
    "            cmd = \"inkscape -z -e {}.png {}.svg\".format(filename[:-4], filename[:-4])\n",
    "            returned_value = subprocess.check_output(cmd, shell=True)\n",
    "        else:\n",
    "            nx.draw(self.graph, with_labels=True)\n",
    "            plt.savefig(filename[:-4] + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "\tdef __init__(self, args):\n",
    "\t\tself.input_text = args['input_text']\n",
    "\t\tself.length = args['length']\n",
    "\t\tself.batch_size = args['batch_size']\n",
    "\t\tself.temperature = args['temperature']\n",
    "\t\tself.model_name = args['model_name']\n",
    "\t\tself.seed = args['seed']\n",
    "\t\tself.nsamples = args['nsamples']\n",
    "\t\tself.cutoffs = args['cutoffs']\n",
    "\t\tself.write_sfdp = args['write_sfdp']\n",
    "\t\tself.random = args['random']\n",
    "                \n",
    "args = Args({\n",
    "\t# 'input_text': os.path.join(data_dir, 'resolved_rapunzel.txt'),\n",
    "\t'input_text': os.path.join(data_dir, 'resolved_zelda_botw.txt'),\n",
    "\t# 'input_text': os.path.join(data_dir, 'zelda-botw.txt'),\n",
    "\t# 'input_text': os.path.join(data_dir, 'rapunzel.txt'),\n",
    "\t# 'input_text': input_text,\n",
    "\t'length': 10,\n",
    "\t'batch_size': 1,\n",
    "\t'temperature': 0.5,\n",
    "\t'model_name' : '117M',\n",
    "\t'seed' : 0,\n",
    "\t'nsamples' : 50,\n",
    "\t'cutoffs' : '11.5 15 12',\n",
    "\t#'cutoffs' : 'fairy',\n",
    "\t'write_sfdp': False,\n",
    "\t'random': False\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rseed = random.randint(0, 1000000)\n",
    "print(rseed)\n",
    "random.seed(0)\n",
    "# 182664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = World([], [], [], [], args)\n",
    "world.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.draw('test.svg')\n",
    "world.export('test.dot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "askBert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
